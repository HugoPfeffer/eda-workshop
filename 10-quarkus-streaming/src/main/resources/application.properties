#
# Quarkus Properties
#
%dev.quarkus.http.port=8090

#
# Quarkus SmallRye Kafka connector
#
# Local Environment
%local.kafka.bootstrap.servers=localhost:9092

# Development Environment
%dev.kafka.bootstrap.servers=event-bus-kafka-bootstrap-eda-workshop.apps.labs.sandbox1862.opentlc.com:443
%dev.kafka.ssl.truststore.password=password
%dev.kafka.ssl.truststore.location=classes/truststore.jks
%dev.kafka.security.protocol=SSL

# Production Environment
kafka.bootstrap.servers=event-bus-kafka-bootstrap:9092

# Consuming data from DBZ topics: Clients
mp.messaging.incoming.dbz-enterprise-clients.connector=smallrye-kafka
mp.messaging.incoming.dbz-enterprise-clients.topic=dbserver.enterprise.clients
mp.messaging.incoming.dbz-enterprise-clients.auto.offset.reset=earliest
%dev.mp.messaging.incoming.dbz-enterprise-clients.group.id=qrk-streaming-clients-dev
mp.messaging.incoming.dbz-enterprise-clients.group.id=qrk-streaming-clients
mp.messaging.incoming.dbz-enterprise-clients.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#mp.messaging.incoming.dbz-enterprise-clients.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
mp.messaging.incoming.dbz-enterprise-clients.value.deserializer=com.redhat.cdc.serde.ClientDBDeserializer

# Consuming data from DBZ topics: Regions
mp.messaging.incoming.dbz-enterprise-regions.connector=smallrye-kafka
mp.messaging.incoming.dbz-enterprise-regions.topic=dbserver.enterprise.regions
mp.messaging.incoming.dbz-enterprise-regions.auto.offset.reset=earliest
%dev.mp.messaging.incoming.dbz-enterprise-regions.group.id=qrk-streaming-regions-dev
mp.messaging.incoming.dbz-enterprise-regions.group.id=qrk-streaming-regions
mp.messaging.incoming.dbz-enterprise-regions.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#mp.messaging.incoming.dbz-enterprise-regions.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
mp.messaging.incoming.dbz-enterprise-regions.value.deserializer=com.redhat.cdc.serde.RegionDBDeserializer

# Consuming data from DBZ topics: Accounts
mp.messaging.incoming.dbz-enterprise-accounts.connector=smallrye-kafka
mp.messaging.incoming.dbz-enterprise-accounts.topic=dbserver.enterprise.accounts
mp.messaging.incoming.dbz-enterprise-accounts.auto.offset.reset=earliest
%dev.mp.messaging.incoming.dbz-enterprise-accounts.group.id=qrk-streaming-accounts-dev
mp.messaging.incoming.dbz-enterprise-accounts.group.id=qrk-streaming-accounts
mp.messaging.incoming.dbz-enterprise-accounts.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#mp.messaging.incoming.dbz-enterprise-accounts.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
mp.messaging.incoming.dbz-enterprise-accounts.value.deserializer=com.redhat.cdc.serde.AccountDBDeserializer

# Consuming data from DBZ topics: Movements
mp.messaging.incoming.dbz-enterprise-movements.connector=smallrye-kafka
mp.messaging.incoming.dbz-enterprise-movements.topic=dbserver.enterprise.movements
mp.messaging.incoming.dbz-enterprise-movements.auto.offset.reset=earliest
%dev.mp.messaging.incoming.dbz-enterprise-movements.group.id=qrk-streaming-movements-dev
mp.messaging.incoming.dbz-enterprise-movements.group.id=qrk-streaming-movements
mp.messaging.incoming.dbz-enterprise-movements.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#mp.messaging.incoming.dbz-enterprise-movements.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
mp.messaging.incoming.dbz-enterprise-movements.value.deserializer=com.redhat.cdc.serde.MovementDBDeserializer

# Kafka Sink - Data Clients
mp.messaging.outgoing.data-clients.connector=smallrye-kafka
mp.messaging.outgoing.data-clients.topic=eda.data.clients
mp.messaging.outgoing.data-clients.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer
mp.messaging.outgoing.data-clients.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer

# Kafka Sink - Data Accounts
mp.messaging.outgoing.data-accounts.connector=smallrye-kafka
mp.messaging.outgoing.data-accounts.topic=eda.data.accounts
mp.messaging.outgoing.data-accounts.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer
mp.messaging.outgoing.data-accounts.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer

# Kafka Sink - Data Regions
mp.messaging.outgoing.data-regions.connector=smallrye-kafka
mp.messaging.outgoing.data-regions.topic=eda.data.regions
mp.messaging.outgoing.data-regions.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer
mp.messaging.outgoing.data-regions.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer

# Kafka Sink - Data Movements
mp.messaging.outgoing.data-movements.connector=smallrye-kafka
mp.messaging.outgoing.data-movements.topic=eda.data.movements
mp.messaging.outgoing.data-movements.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer
mp.messaging.outgoing.data-movements.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer

# Kafka Sink - Alerts
mp.messaging.outgoing.eda-alerts.connector=smallrye-kafka
# To allow multiple streams
mp.messaging.outgoing.eda-alerts.merge=true
mp.messaging.outgoing.eda-alerts.topic=eda.events.alerts
mp.messaging.outgoing.eda-alerts.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer
mp.messaging.outgoing.eda-alerts.value.serializer=org.apache.kafka.common.serialization.StringSerializer

## Kafka Sink - Aggregate metrics
#mp.messaging.outgoing.eda-aggregate-metrics.connector=smallrye-kafka
## To allow multiple streams
#mp.messaging.outgoing.eda-aggregate-metrics.merge=true
#mp.messaging.outgoing.eda-aggregate-metrics.topic=eda.events.aggregate-metrics
#mp.messaging.outgoing.eda-aggregate-metrics.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer
#mp.messaging.outgoing.eda-aggregate-metrics.value.serializer=org.apache.kafka.common.serialization.StringSerializer

#
# Quarkus Kafka Streams
#

# Development Environment
%dev.quarkus.kafka-streams.bootstrap-servers=event-bus-kafka-bootstrap-eda-workshop.apps.labs.sandbox1862.opentlc.com:443
%dev.quarkus.kafka-streams.ssl.truststore.password=password
%dev.quarkus.kafka-streams.ssl.truststore.location=classes/truststore.jks
%dev.quarkus.kafka-streams.security.protocol=SSL

# Production Environment
quarkus.kafka-streams.bootstrap-servers=event-bus-kafka-bootstrap:9092

# Region and Accounts Aggregation Streams
%dev.quarkus.kafka-streams.application-id=quarkus-streaming-dev
quarkus.kafka-streams.application-id=quarkus-streaming
#quarkus.kafka-streams.topics=eda.data.clients,eda.data.accounts,eda.data.movements,eda.data.regions
quarkus.kafka-streams.topics=eda.data.clients,eda.data.accounts,eda.data.movements

# streams options
kafka-streams.auto.offset.reset=earliest
kafka-streams.consumer.session.timeout.ms=250
kafka-streams.consumer.heartbeat.interval.ms=200
#kafka-streams.cache.max.bytes.buffering=10240
#kafka-streams.commit.interval.ms=1000
#kafka-streams.metadata.max.age.ms=500
#kafka-streams.metrics.recording.level=DEBUG

## Use sub-folder of embedded broker, so it gets cleaned by KafkaResource between re-runs
## This does not work for native tests, manually clean-up /tmp/kafka-streams/temperature-aggregator
#%test.kafka-streams.state.dir=target/data/kafka-data/stores
